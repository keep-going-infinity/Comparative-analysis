{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15480,
     "status": "ok",
     "timestamp": 1700589069980,
     "user": {
      "displayName": "Adam Mabrouk",
      "userId": "04204959827212434409"
     },
     "user_tz": 0
    },
    "id": "vcFtthY88viQ",
    "outputId": "dc8216d1-9f3a-49dd-8492-aadb98f16608",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Dissertation Project: An Empirical Study on the Classification \n",
    "# Performance of Deep Learning vs. Gradient Boosting \n",
    "# on heterogeneous tabular data\n",
    "#\n",
    "# This notebook provides functions for the preprocessing of the \n",
    "# lending Club dataset. \n",
    "#\n",
    "# Author: Adam Mabrouk\n",
    "# Supervisor: Ben Ralph\n",
    "# Institution: University of Bath\n",
    "# Created on: 01/01/2024\n",
    "# Version: 1.0 \n",
    "\n",
    "# Acknowledgments:\n",
    "\n",
    "# The cleaning pipeline is based on the literature (not code)\n",
    "# of Authors: Shi, S., Tse, R., Luo, W., Dâ€™Addona, \n",
    "# S. and Pau, G., 2022. Machine learning-driven credit risk: \n",
    "# a systemic review. Neural Computing and Applications, 34(17), \n",
    "# pp.14327-14339.\n",
    "\n",
    "# Malekipirbazari, M. and Aksakalli, V., 2015. \n",
    "# Risk assessment in social lending via random forests. \n",
    "# Expert Systems with Applications, 42(10), pp.4621-4631.\n",
    "\n",
    "# Demajo, L.M., Vella, V. and Dingli, A., 2020. \n",
    "# Explainable ai for interpretable credit scoring. \n",
    "# arXiv preprint arXiv:2012.03749.\n",
    "# # -----------------------------------------------------------\n",
    "# Libraries and versions\n",
    "# ----------------------\n",
    "# Python version: 3.11.5 \n",
    "# numpy: 1.24.3\n",
    "# pandas: 2.0.3\n",
    "\n",
    "# Import standard libraries for data handling,  \n",
    "from datetime import datetime # filtering dataset. \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuK91lNI84fo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    \"\"\"The DataCleaner class cleans the Lending Club dataset. \"\"\"\n",
    "\n",
    "    def __init__(self, lending_club_file_path):\n",
    "        \"\"\" Constructor reads Lending Club file path.\n",
    "        Args:\n",
    "            lending_club_file_path 'accepted_2007_to_2018Q4.csv' (str)\"\"\"\n",
    "\n",
    "        self.lending_club_file_path = lending_club_file_path\n",
    "        self.data = pd.read_csv(self.lending_club_file_path, low_memory=False)\n",
    "        self.load_and_filter_data()\n",
    "        self.initial_column_count = len(self.data.columns)\n",
    "\n",
    "    def load_and_filter_data(self):\n",
    "        \"\"\" This function filters the Lending Club dataset to years: 2012-01-01 - 2016-01-01. These years \n",
    "        represent more economoic stability, post 2007 recession and prior to the COVID pandemic. \"\"\"\n",
    "\n",
    "        if 'issue_d' in self.data.columns:\n",
    "            self.data['issue_d'] = pd.to_datetime(self.data['issue_d'], format='%b-%Y')\n",
    "            start_date = pd.Timestamp('2012-01-01')\n",
    "            end_date = pd.Timestamp('2016-01-01') # changed from '2016-09-30' to '2016-01-01'\n",
    "            self.data = self.data.loc[(self.data['issue_d'] >= start_date) & (self.data['issue_d'] <= end_date)]\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "        \"\"\" This function removes duplicate rows from the dataset. \"\"\"\n",
    "\n",
    "        original_rows = len(self.data)\n",
    "        self.data = self.data.drop_duplicates().reset_index(drop=True)\n",
    "        duplicates_dropped = original_rows - len(self.data)\n",
    "\n",
    "    def remove_columns_less_than_30_Percent(self):\n",
    "        \"\"\" This function removes columns with more than 30% of missing values.\"\"\"\n",
    "\n",
    "        original_columns = len(self.data.columns)\n",
    "        self.data = self.data.loc[:, self.data.isnull().mean() < 0.3]\n",
    "        remaining_columns = len(self.data.columns)\n",
    "        self.columns_with_missing_data = original_columns - remaining_columns\n",
    "\n",
    "    def select_features(self):\n",
    "        \"\"\" This function selects specific features from the dataset that contribute to the\n",
    "        credit risk prediction model. As the focus of this project is tabular data, a detailed \n",
    "        note is made on the type of features, which is shown below.\"\"\"\n",
    "\n",
    "        chosen_columns = [\"annual_inc\",    # Continuous\n",
    "                          \"dti\",           # Continuous\n",
    "                          \"installment\",   # Continuous\n",
    "                          \"int_rate\",      # Continuous\n",
    "                          \"loan_amnt\",     # Continuous\n",
    "                          \"revol_bal\",     # Continuous\n",
    "                          \"revol_util\",    # Continuous\n",
    "                          \"open_acc\",      # Discrete\n",
    "                          \"delinq_2yrs\",   # Discrete\n",
    "                          \"total_acc\",     # Discrete\n",
    "                          \"emp_length\",    # Categorical\n",
    "                          \"grade\",         # Categorical\n",
    "                          \"home_ownership\",# Categorical\n",
    "                          \"purpose\",       # Categorical\n",
    "                          \"sub_grade\",     # Categorical\n",
    "                          \"term\",          # Categorical\n",
    "                          \"loan_status\"]   # Categorical \"\"\"Target\"\"\"\n",
    "\n",
    "        self.data = self.data[chosen_columns]\n",
    "\n",
    "    def adjust_variables(self):\n",
    "        \"\"\"\n",
    "        This function adjusts the categorical variable home_ownership by \n",
    "        filtering out rows where 'home_ownership' is 'NONE', 'OTHER', or 'ANY'.\n",
    "        \"\"\"\n",
    "        self.data = self.data[~self.data[\"home_ownership\"].isin(['NONE', 'OTHER', 'ANY'])]\n",
    "\n",
    "    def adjust_dependent_variable(self):\n",
    "        \"\"\" This function drops terms from the loan status feature that are not\n",
    "        specific to loan default (bad credit risk).\"\"\"\n",
    "\n",
    "        self.data = self.data[~self.data['loan_status'].isin(['Current', 'In Grace Period', 'Late (16-30 days)'])]\n",
    "        self.data.dropna(inplace=True)\n",
    "\n",
    "    def select_dependent_variable_values(self):\n",
    "        \"\"\" This function selects rows with appropriate terms that are specific to loan default (bad credit risk) and\n",
    "        good credit risk for the loan status feature. \"\"\"\n",
    "\n",
    "        self.data = self.data[self.data['loan_status'].isin(['Fully Paid', 'Charged Off', 'Default', 'Late (31-120 days)'])]\n",
    "\n",
    "    def y_class_mapping(self):\n",
    "        \"\"\"\n",
    "        This function sets dependent variable (labels) to 1 for good loans, 0 for bad loans\n",
    "        using manual binary encoding from multiple labels. All classification models are binary\n",
    "\n",
    "        'Fully Paid' loans are considered as good credit risk and encoded as 1.\n",
    "        'Charged Off', 'Default', 'Late (31-120 days)' loans are considered as bad credit risk and encoded as 0.\n",
    "        \"\"\"\n",
    "\n",
    "        self.label_column = 'loan_status'\n",
    "        self.label_mapping = {\n",
    "            'Fully Paid': 1,\n",
    "            'Charged Off': 0,\n",
    "            'Late (31-120 days)': 0,\n",
    "            'Default': 0}\n",
    "\n",
    "        self.data[self.label_column] = self.data[self.label_column].map(self.label_mapping)\n",
    "\n",
    "    def save_data(self, file_path):\n",
    "        \"\"\" Save the cleaned data to a CSV file.\n",
    "        Args:\n",
    "            file_path (str): cleaned Lending Club data saved as LendingClubDataCleaner.csv\"\"\"\n",
    "        self.data.to_csv(file_path, index=False)\n",
    "\n",
    "    def cleaned_data(self):\n",
    "        \"\"\"\n",
    "        This function enables the user to runs all cleaned features in the dataset.\n",
    "        \"\"\"\n",
    "        self.remove_duplicates()\n",
    "        self.remove_columns_less_than_30_Percent()\n",
    "        self.select_features()\n",
    "        self.adjust_variables()\n",
    "        self.adjust_dependent_variable()\n",
    "        self.select_dependent_variable_values()\n",
    "        self.y_class_mapping()\n",
    "\n",
    "cleaned = DataCleaner(\"raw_datasets/01_LendingClubData_2007_to_2018Q4.csv\")\n",
    "cleaned.cleaned_data()\n",
    "cleaned.save_data(\"cleaned_data/lending_club_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1700589829706,
     "user": {
      "displayName": "Adam Mabrouk",
      "userId": "04204959827212434409"
     },
     "user_tz": 0
    },
    "id": "g_vNIPbjBZkG",
    "outputId": "91f9a637-1647-4ab0-84d5-526f52810261",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSb3D9mvBrFX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPcNV7POOdz+CN/6IWDqgpu",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
